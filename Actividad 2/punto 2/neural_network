import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.neural_network import MLPClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.utils.class_weight import compute_class_weight
import numpy as np


#1. Load the dataset from the CSV file
df = pd.read_csv("heart_disease_dataset.csv")


#2. separate featrures and target
X = df.drop('heart_disease', axis=1) #this line drops the target column from the feature set, it gets it by name and with axix=1 it drops the column
y = df['heart_disease'] #this line selects the target column from the dataframe, it gets it by name and assigns it to y


#3.define numeric and categorical columns and split them into separate dataframes
numeric_features = [
    "age",
    "trestbps",
    "chol",
    "thalach",
    "oldpeak",
    "bmi"
]
categorical_features = [
    "sex",
    "cp",
    "fbs",
    "restecg",
    "exang",    
    "slope",
    "ca",
    "thal",
    "smoking",
    "diabetes"
]

x_numeric = X[numeric_features]
x_categorical = X[categorical_features]


# 4. Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# set weights 
classes = np.unique(y_train)
class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)
weights = {k: v for k, v in zip(classes, class_weights)}

# Create array of weights with the sample
sample_weights = np.array([weights[i] for i in y_train])


# 5. preprocess the numeric features
preprocessor = ColumnTransformer(
    transformers=[
        ("numeric", StandardScaler(), numeric_features),  # Escale numeric features
        ("categoric", OneHotEncoder(handle_unknown="ignore"), categorical_features)  #Encode categorical features
    ]
)


# 6. Pipeline with preprocessing and model
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", MLPClassifier(
        hidden_layer_sizes=(128, 64),  # more capacity for complex patterns
        activation='relu',
        solver='adam',
        alpha=0.0005,                 # regularization term
        batch_size='auto',
        learning_rate='adaptive',
        max_iter=1000,                 #max epochs
        random_state=42,
        early_stopping=True,           # stop if no improvement
        n_iter_no_change=20
    ))
])

# 7. Train the model
model.fit(X_train, y_train, classifier__sample_weight=sample_weights)


# 8. Evaluate the model
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Reporte:\n", classification_report(y_test, y_pred))


cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["No sick", "sick"], yticklabels=["no sick", "sick"])
plt.xlabel("Predicted")
plt.ylabel("Real")
plt.title("confusion matrix")

plt.show()
